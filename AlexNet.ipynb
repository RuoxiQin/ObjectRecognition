{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from caffe_classes import class_names\n",
    "from gen_train import input_func\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training phase:\n",
      "Step 0 training\n",
      "the logit is:\n",
      "[[232.05957]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 0 training\n",
      "the logit is:\n",
      "[[368.56927]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 1 training\n",
      "Step 1 training\n",
      "Step 2 training\n",
      "Step 2 training\n",
      "Step 3 training\n",
      "Step 3 training\n",
      "Step 4 training\n",
      "Step 4 training\n",
      "Step 5 training\n",
      "the logit is:\n",
      "[[915.78845]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 5 training\n",
      "the logit is:\n",
      "[[946.7526]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 6 training\n",
      "Step 6 training\n",
      "Step 7 training\n",
      "Step 7 training\n",
      "Step 8 training\n",
      "Step 8 training\n",
      "Step 9 training\n",
      "Step 9 training\n",
      "Step 10 training\n",
      "the logit is:\n",
      "[[1121.4528]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 10 training\n",
      "the logit is:\n",
      "[[1133.1296]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 11 training\n",
      "Step 11 training\n",
      "Step 12 training\n",
      "Step 12 training\n",
      "Step 13 training\n",
      "Step 13 training\n",
      "Step 14 training\n",
      "Step 14 training\n",
      "Step 15 training\n",
      "the logit is:\n",
      "[[1200.8173]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 15 training\n",
      "the logit is:\n",
      "[[1205.4244]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 16 training\n",
      "Step 16 training\n",
      "Step 17 training\n",
      "Step 17 training\n",
      "Step 18 training\n",
      "Step 18 training\n",
      "Step 19 training\n",
      "Step 19 training\n",
      "Step 20 training\n",
      "the logit is:\n",
      "[[1232.0336]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 20 training\n",
      "the logit is:\n",
      "[[1233.8491]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 21 training\n",
      "Step 21 training\n",
      "Step 22 training\n",
      "Step 22 training\n",
      "Step 23 training\n",
      "Step 23 training\n",
      "Step 24 training\n",
      "Step 24 training\n",
      "Step 25 training\n",
      "the logit is:\n",
      "[[1244.1896]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 25 training\n",
      "the logit is:\n",
      "[[1244.9021]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 26 training\n",
      "Step 26 training\n",
      "Step 27 training\n",
      "Step 27 training\n",
      "Step 28 training\n",
      "Step 28 training\n",
      "Step 29 training\n",
      "Step 29 training\n",
      "Step 30 training\n",
      "the logit is:\n",
      "[[1248.8558]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 30 training\n",
      "the logit is:\n",
      "[[1249.1395]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 31 training\n",
      "Step 31 training\n",
      "Step 32 training\n",
      "Step 32 training\n",
      "Step 33 training\n",
      "Step 33 training\n",
      "Step 34 training\n",
      "Step 34 training\n",
      "Step 35 training\n",
      "the logit is:\n",
      "[[1250.6239]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 35 training\n",
      "the logit is:\n",
      "[[1250.7432]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 36 training\n",
      "Step 36 training\n",
      "Step 37 training\n",
      "Step 37 training\n",
      "Step 38 training\n",
      "Step 38 training\n",
      "Step 39 training\n",
      "Step 39 training\n",
      "Step 40 training\n",
      "the logit is:\n",
      "[[1251.2886]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 40 training\n",
      "the logit is:\n",
      "[[1251.3446]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 41 training\n",
      "Step 41 training\n",
      "Step 42 training\n",
      "Step 42 training\n",
      "Step 43 training\n",
      "Step 43 training\n",
      "Step 44 training\n",
      "Step 44 training\n",
      "Step 45 training\n",
      "the logit is:\n",
      "[[1251.5348]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 45 training\n",
      "the logit is:\n",
      "[[1251.5674]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 46 training\n",
      "Step 46 training\n",
      "Step 47 training\n",
      "Step 47 training\n",
      "Step 48 training\n",
      "Step 48 training\n",
      "Step 49 training\n",
      "Step 49 training\n",
      "Step 50 training\n",
      "the logit is:\n",
      "[[1251.6251]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 50 training\n",
      "the logit is:\n",
      "[[1251.6505]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 51 training\n",
      "Step 51 training\n",
      "Step 52 training\n",
      "Step 52 training\n",
      "Step 53 training\n",
      "Step 53 training\n",
      "Step 54 training\n",
      "Step 54 training\n",
      "Step 55 training\n",
      "the logit is:\n",
      "[[1251.66]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 55 training\n",
      "the logit is:\n",
      "[[1251.6805]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 56 training\n",
      "Step 56 training\n",
      "Step 57 training\n",
      "Step 57 training\n",
      "Step 58 training\n",
      "Step 58 training\n",
      "Step 59 training\n",
      "Step 59 training\n",
      "Step 60 training\n",
      "the logit is:\n",
      "[[1251.6716]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 60 training\n",
      "the logit is:\n",
      "[[1251.6915]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 61 training\n",
      "Step 61 training\n",
      "Step 62 training\n",
      "Step 62 training\n",
      "Step 63 training\n",
      "Step 63 training\n",
      "Step 64 training\n",
      "Step 64 training\n",
      "Step 65 training\n",
      "the logit is:\n",
      "[[1251.6757]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 65 training\n",
      "the logit is:\n",
      "[[1251.6958]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 66 training\n",
      "Step 66 training\n",
      "Step 67 training\n",
      "Step 67 training\n",
      "Step 68 training\n",
      "Step 68 training\n",
      "Step 69 training\n",
      "Step 69 training\n",
      "Step 70 training\n",
      "the logit is:\n",
      "[[1251.6774]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 70 training\n",
      "the logit is:\n",
      "[[1251.6979]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 71 training\n",
      "Step 71 training\n",
      "Step 72 training\n",
      "Step 72 training\n",
      "Step 73 training\n",
      "Step 73 training\n",
      "Step 74 training\n",
      "Step 74 training\n",
      "Step 75 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 75 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 76 training\n",
      "Step 76 training\n",
      "Step 77 training\n",
      "Step 77 training\n",
      "Step 78 training\n",
      "Step 78 training\n",
      "Step 79 training\n",
      "Step 79 training\n",
      "Step 80 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 80 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 81 training\n",
      "Step 81 training\n",
      "Step 82 training\n",
      "Step 82 training\n",
      "Step 83 training\n",
      "Step 83 training\n",
      "Step 84 training\n",
      "Step 84 training\n",
      "Step 85 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 85 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 86 training\n",
      "Step 86 training\n",
      "Step 87 training\n",
      "Step 87 training\n",
      "Step 88 training\n",
      "Step 88 training\n",
      "Step 89 training\n",
      "Step 89 training\n",
      "Step 90 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 90 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 91 training\n",
      "Step 91 training\n",
      "Step 92 training\n",
      "Step 92 training\n",
      "Step 93 training\n",
      "Step 93 training\n",
      "Step 94 training\n",
      "Step 94 training\n",
      "Step 95 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 95 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 96 training\n",
      "Step 96 training\n",
      "Step 97 training\n",
      "Step 97 training\n",
      "Step 98 training\n",
      "Step 98 training\n",
      "Step 99 training\n",
      "Step 99 training\n",
      "Step 100 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 100 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 101 training\n",
      "Step 101 training\n",
      "Step 102 training\n",
      "Step 102 training\n",
      "Step 103 training\n",
      "Step 103 training\n",
      "Step 104 training\n",
      "Step 104 training\n",
      "Step 105 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 105 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 106 training\n",
      "Step 106 training\n",
      "Step 107 training\n",
      "Step 107 training\n",
      "Step 108 training\n",
      "Step 108 training\n",
      "Step 109 training\n",
      "Step 109 training\n",
      "Step 110 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 110 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 111 training\n",
      "Step 111 training\n",
      "Step 112 training\n",
      "Step 112 training\n",
      "Step 113 training\n",
      "Step 113 training\n",
      "Step 114 training\n",
      "Step 114 training\n",
      "Step 115 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 115 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 116 training\n",
      "Step 116 training\n",
      "Step 117 training\n",
      "Step 117 training\n",
      "Step 118 training\n",
      "Step 118 training\n",
      "Step 119 training\n",
      "Step 119 training\n",
      "Step 120 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 120 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 121 training\n",
      "Step 121 training\n",
      "Step 122 training\n",
      "Step 122 training\n",
      "Step 123 training\n",
      "Step 123 training\n",
      "Step 124 training\n",
      "Step 124 training\n",
      "Step 125 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 125 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 126 training\n",
      "Step 126 training\n",
      "Step 127 training\n",
      "Step 127 training\n",
      "Step 128 training\n",
      "Step 128 training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 129 training\n",
      "Step 129 training\n",
      "Step 130 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 130 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 131 training\n",
      "Step 131 training\n",
      "Step 132 training\n",
      "Step 132 training\n",
      "Step 133 training\n",
      "Step 133 training\n",
      "Step 134 training\n",
      "Step 134 training\n",
      "Step 135 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 135 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 136 training\n",
      "Step 136 training\n",
      "Step 137 training\n",
      "Step 137 training\n",
      "Step 138 training\n",
      "Step 138 training\n",
      "Step 139 training\n",
      "Step 139 training\n",
      "Step 140 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 140 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 141 training\n",
      "Step 141 training\n",
      "Step 142 training\n",
      "Step 142 training\n",
      "Step 143 training\n",
      "Step 143 training\n",
      "Step 144 training\n",
      "Step 144 training\n",
      "Step 145 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 145 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 146 training\n",
      "Step 146 training\n",
      "Step 147 training\n",
      "Step 147 training\n",
      "Step 148 training\n",
      "Step 148 training\n",
      "Step 149 training\n",
      "Step 149 training\n",
      "Step 150 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 150 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 151 training\n",
      "Step 151 training\n",
      "Step 152 training\n",
      "Step 152 training\n",
      "Step 153 training\n",
      "Step 153 training\n",
      "Step 154 training\n",
      "Step 154 training\n",
      "Step 155 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 155 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 156 training\n",
      "Step 156 training\n",
      "Step 157 training\n",
      "Step 157 training\n",
      "Step 158 training\n",
      "Step 158 training\n",
      "Step 159 training\n",
      "Step 159 training\n",
      "Step 160 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 160 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 161 training\n",
      "Step 161 training\n",
      "Step 162 training\n",
      "Step 162 training\n",
      "Step 163 training\n",
      "Step 163 training\n",
      "Step 164 training\n",
      "Step 164 training\n",
      "Step 165 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 165 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 166 training\n",
      "Step 166 training\n",
      "Step 167 training\n",
      "Step 167 training\n",
      "Step 168 training\n",
      "Step 168 training\n",
      "Step 169 training\n",
      "Step 169 training\n",
      "Step 170 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 170 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 171 training\n",
      "Step 171 training\n",
      "Step 172 training\n",
      "Step 172 training\n",
      "Step 173 training\n",
      "Step 173 training\n",
      "Step 174 training\n",
      "Step 174 training\n",
      "Step 175 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 175 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 176 training\n",
      "Step 176 training\n",
      "Step 177 training\n",
      "Step 177 training\n",
      "Step 178 training\n",
      "Step 178 training\n",
      "Step 179 training\n",
      "Step 179 training\n",
      "Step 180 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 180 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 181 training\n",
      "Step 181 training\n",
      "Step 182 training\n",
      "Step 182 training\n",
      "Step 183 training\n",
      "Step 183 training\n",
      "Step 184 training\n",
      "Step 184 training\n",
      "Step 185 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 185 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 186 training\n",
      "Step 186 training\n",
      "Step 187 training\n",
      "Step 187 training\n",
      "Step 188 training\n",
      "Step 188 training\n",
      "Step 189 training\n",
      "Step 189 training\n",
      "Step 190 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 190 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 191 training\n",
      "Step 191 training\n",
      "Step 192 training\n",
      "Step 192 training\n",
      "Step 193 training\n",
      "Step 193 training\n",
      "Step 194 training\n",
      "Step 194 training\n",
      "Step 195 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 195 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 196 training\n",
      "Step 196 training\n",
      "Step 197 training\n",
      "Step 197 training\n",
      "Step 198 training\n",
      "Step 198 training\n",
      "Step 199 training\n",
      "Step 199 training\n",
      "Step 200 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 200 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 201 training\n",
      "Step 201 training\n",
      "Step 202 training\n",
      "Step 202 training\n",
      "Step 203 training\n",
      "Step 203 training\n",
      "Step 204 training\n",
      "Step 204 training\n",
      "Step 205 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 205 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 206 training\n",
      "Step 206 training\n",
      "Step 207 training\n",
      "Step 207 training\n",
      "Step 208 training\n",
      "Step 208 training\n",
      "Step 209 training\n",
      "Step 209 training\n",
      "Step 210 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 210 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 211 training\n",
      "Step 211 training\n",
      "Step 212 training\n",
      "Step 212 training\n",
      "Step 213 training\n",
      "Step 213 training\n",
      "Step 214 training\n",
      "Step 214 training\n",
      "Step 215 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 215 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 216 training\n",
      "Step 216 training\n",
      "Step 217 training\n",
      "Step 217 training\n",
      "Step 218 training\n",
      "Step 218 training\n",
      "Step 219 training\n",
      "Step 219 training\n",
      "Step 220 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 220 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 221 training\n",
      "Step 221 training\n",
      "Step 222 training\n",
      "Step 222 training\n",
      "Step 223 training\n",
      "Step 223 training\n",
      "Step 224 training\n",
      "Step 224 training\n",
      "Step 225 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 225 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 226 training\n",
      "Step 226 training\n",
      "Step 227 training\n",
      "Step 227 training\n",
      "Step 228 training\n",
      "Step 228 training\n",
      "Step 229 training\n",
      "Step 229 training\n",
      "Step 230 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 230 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 231 training\n",
      "Step 231 training\n",
      "Step 232 training\n",
      "Step 232 training\n",
      "Step 233 training\n",
      "Step 233 training\n",
      "Step 234 training\n",
      "Step 234 training\n",
      "Step 235 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 235 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 236 training\n",
      "Step 236 training\n",
      "Step 237 training\n",
      "Step 237 training\n",
      "Step 238 training\n",
      "Step 238 training\n",
      "Step 239 training\n",
      "Step 239 training\n",
      "Step 240 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 240 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 241 training\n",
      "Step 241 training\n",
      "Step 242 training\n",
      "Step 242 training\n",
      "Step 243 training\n",
      "Step 243 training\n",
      "Step 244 training\n",
      "Step 244 training\n",
      "Step 245 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 245 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 246 training\n",
      "Step 246 training\n",
      "Step 247 training\n",
      "Step 247 training\n",
      "Step 248 training\n",
      "Step 248 training\n",
      "Step 249 training\n",
      "Step 249 training\n",
      "Step 250 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 250 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 251 training\n",
      "Step 251 training\n",
      "Step 252 training\n",
      "Step 252 training\n",
      "Step 253 training\n",
      "Step 253 training\n",
      "Step 254 training\n",
      "Step 254 training\n",
      "Step 255 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 255 training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 256 training\n",
      "Step 256 training\n",
      "Step 257 training\n",
      "Step 257 training\n",
      "Step 258 training\n",
      "Step 258 training\n",
      "Step 259 training\n",
      "Step 259 training\n",
      "Step 260 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 260 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 261 training\n",
      "Step 261 training\n",
      "Step 262 training\n",
      "Step 262 training\n",
      "Step 263 training\n",
      "Step 263 training\n",
      "Step 264 training\n",
      "Step 264 training\n",
      "Step 265 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 265 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 266 training\n",
      "Step 266 training\n",
      "Step 267 training\n",
      "Step 267 training\n",
      "Step 268 training\n",
      "Step 268 training\n",
      "Step 269 training\n",
      "Step 269 training\n",
      "Step 270 training\n",
      "the logit is:\n",
      "[[1251.6781]]\n",
      "The loss is:\n",
      "0.0\n",
      "The ground truth is:\n",
      "[[1.]]\n",
      "Step 270 training\n",
      "the logit is:\n",
      "[[1251.698]]\n",
      "The loss is:\n",
      "1.0\n",
      "The ground truth is:\n",
      "[[0.]]\n",
      "Step 271 training\n",
      "Step 271 training\n",
      "Step 272 training\n",
      "Step 272 training\n",
      "Step 273 training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-08f1fb22b38b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m             {input_object: features[\"objects\"], \n\u001b[1;32m     46\u001b[0m             \u001b[0mground_truth\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             mode_is_train: True})\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   2283\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m     \"\"\"\n\u001b[0;32m-> 2285\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2287\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4934\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4935\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 4936\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LEARN_RATE = 0.1\n",
    "TRAIN_STEPS = 301\n",
    "\n",
    "mode_is_train = tf.placeholder(tf.bool)\n",
    "# Input layers\n",
    "input_object = tf.placeholder(tf.float32, [None, 4096])\n",
    "ground_truth = tf.placeholder(tf.float32, [None, 1])\n",
    "# Add 1 fully connected hidden layer after the cnn\n",
    "dense1 = tf.layers.dense(inputs=input_object, units=8192, \n",
    "    activation=tf.sigmoid)\n",
    "dropout1 = tf.layers.dropout(inputs=dense1, rate=0.5, training = mode_is_train)\n",
    "logits = tf.layers.dense(inputs=dropout1, units=1)\n",
    "sig_logits = tf.sigmoid(logits)\n",
    "# define loss function\n",
    "loss = tf.subtract(sig_logits, ground_truth)\n",
    "loss = tf.square(loss)\n",
    "loss = tf.reduce_mean(loss)\n",
    "# add optimizer, this a symbolic ops to do gradient descent\n",
    "optimizer = tf.train.AdamOptimizer(LEARN_RATE)\n",
    "train_step = optimizer.minimize(loss)\n",
    "# initializer\n",
    "init = tf.global_variables_initializer()\n",
    "# Train and test the result\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    features = {}\n",
    "    features[\"objects\"] = np.random.rand(2, 4096).astype(np.float32)\n",
    "    #labels = np.random.randint(0, 2, size=(1, 1)).astype(np.float32)\n",
    "    labels = np.array([1.0]).reshape((-1, 1)).astype(np.float32)\n",
    "    \n",
    "    feature1 = features[\"objects\"][0]\n",
    "    feature2 = features[\"objects\"][1]\n",
    "\n",
    "\n",
    "\n",
    "    # Training phase\n",
    "    print(\"In training phase:\")\n",
    "    for step in range(TRAIN_STEPS):\n",
    "        \n",
    "        features[\"objects\"] = feature1.reshape((1, 4096))\n",
    "        labels = np.array([1.0]).reshape((-1, 1)).astype(np.float32)\n",
    "        print(\"Step %d training\" % step)\n",
    "        train_step.run(feed_dict=\n",
    "            {input_object: features[\"objects\"], \n",
    "            ground_truth: labels, \n",
    "            mode_is_train: True})\n",
    "\n",
    "\n",
    "        # Save the model and Print the accuracy periodically\n",
    "        if step % 5 == 0:\n",
    "            print('the logit is:')\n",
    "            print(sess.run(logits, feed_dict=\n",
    "                {input_object: features[\"objects\"], \n",
    "                ground_truth:labels, mode_is_train: False}))\n",
    "            print(\"The loss is:\")\n",
    "            print(loss.eval(feed_dict=\n",
    "                {input_object: features[\"objects\"], \n",
    "                ground_truth:labels, mode_is_train: False}))\n",
    "            print(\"The ground truth is:\")\n",
    "            print(ground_truth.eval(feed_dict=\n",
    "                {input_object: features[\"objects\"], \n",
    "                ground_truth:labels, mode_is_train: False}))\n",
    "            \n",
    "        features[\"objects\"] = feature2.reshape((1, 4096))\n",
    "        labels = np.array([0.0]).reshape((-1, 1)).astype(np.float32)\n",
    "        print(\"Step %d training\" % step)\n",
    "        train_step.run(feed_dict=\n",
    "            {input_object: features[\"objects\"], \n",
    "            ground_truth: labels, \n",
    "            mode_is_train: True})\n",
    "\n",
    "\n",
    "        # Save the model and Print the accuracy periodically\n",
    "        if step % 5 == 0:\n",
    "            print('the logit is:')\n",
    "            print(sess.run(logits, feed_dict=\n",
    "                {input_object: features[\"objects\"], \n",
    "                ground_truth:labels, mode_is_train: False}))\n",
    "            print(\"The loss is:\")\n",
    "            print(loss.eval(feed_dict=\n",
    "                {input_object: features[\"objects\"], \n",
    "                ground_truth:labels, mode_is_train: False}))\n",
    "            print(\"The ground truth is:\")\n",
    "            print(ground_truth.eval(feed_dict=\n",
    "                {input_object: features[\"objects\"], \n",
    "                ground_truth:labels, mode_is_train: False}))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
