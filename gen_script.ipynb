{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os.path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET SORTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init parameters\n",
    "\n",
    "path_prefix = '../CS640_Project_dataset/'\n",
    "dir_prefix = 'scene_'\n",
    "obj_suffix = '.JPG'\n",
    "file_scene = 'scene.jpg'\n",
    "file_xml = 'scene.xml'\n",
    "obj_dim = 500\n",
    "\n",
    "ikea_scenes = [\n",
    "    'bathroom', 'bedroom', 'childrenroom', \n",
    "    'hallway', 'homeoffice', 'kitchen', \n",
    "    'laundry', 'livingroom', 'outdoor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the dataset_structure\n",
    "\n",
    "def scan_num_obj(path):\n",
    "    i = 0\n",
    "    if not os.path.exists(path + '/' + file_xml):\n",
    "        return i\n",
    "    while True:\n",
    "        fname = path + '/' + str(i+1) + obj_suffix\n",
    "        if os.path.exists(fname):\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "    return i\n",
    "\n",
    "def scan_scene(path_to_scene):\n",
    "    count = []\n",
    "    i = 1\n",
    "    while True:\n",
    "        path_name = path_to_scene + '/' + dir_prefix + str(i)\n",
    "        i += 1 \n",
    "        if os.path.exists(path_name):\n",
    "            count.append(scan_num_obj(path_name))\n",
    "        else:\n",
    "            break\n",
    "    return count\n",
    "\n",
    "def scan_all(path_to_data):\n",
    "    output = []\n",
    "    for x in ikea_scenes:\n",
    "        output.append(scan_scene(path_to_data + '/' + x))\n",
    "    return output\n",
    "\n",
    "dataset_structure = scan_all(path_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backtrack the path to the objects\n",
    "\n",
    "def backtrack_path(target_num, path_to_data):\n",
    "    scene_loc = 0\n",
    "    scene_num = 0\n",
    "    found = False\n",
    "    for x in dataset_structure:\n",
    "        for y in x:\n",
    "            if (target_num <= y):\n",
    "                found = True\n",
    "                break\n",
    "            else: \n",
    "                target_num -= y\n",
    "                scene_num += 1\n",
    "        if found:\n",
    "            break\n",
    "        scene_loc += 1\n",
    "    return (scene_loc, scene_num + 1, target_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATE TRAINING PICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get obj from xml \n",
    "def bound_xml(tup, path):\n",
    "    path_to_xml = path + ikea_scenes[tup[0]] + '/' \\\n",
    "            + dir_prefix + str(tup[1]) + '/' \\\n",
    "            + file_xml\n",
    "    target_obj = tup[2] \n",
    "    \n",
    "    # XML parsing\n",
    "    found = False \n",
    "    tree = ET.parse(path_to_xml)\n",
    "    root = tree.getroot()\n",
    "    for obj in root.iter('object'):\n",
    "        if(obj.find('deleted').text == \"0\") and obj.find('name').text == str(target_obj):\n",
    "            x_list = []\n",
    "            y_list = []\n",
    "            for pt in obj.iter('pt'):\n",
    "                x = int(pt.find('x').text)\n",
    "                y = int(pt.find('y').text)\n",
    "                x_list.append(x)\n",
    "                y_list.append(y)\n",
    "            Found = True # Found!\n",
    "            break\n",
    "        else: \n",
    "            continue \n",
    "    if Found:\n",
    "        return min(x_list), max(x_list), min(y_list), max(y_list)\n",
    "    else: \n",
    "        return 0,0,0,0\n",
    "\n",
    "# backtrack path \n",
    "def backtrack_tuple(tup, path):\n",
    "    return (path + ikea_scenes[tup[0]] + '/' \\\n",
    "            + dir_prefix + str(tup[1]) + '/' \\\n",
    "            + str(tup[2]) + obj_suffix)\n",
    "\n",
    "# cropping script \n",
    "def img_crop(img, dim = (227, 227), loc = None):\n",
    "    if loc == None:\n",
    "        a = img.shape\n",
    "        loc = [(0,0), (a[0] - 1, a[1] - 1)]\n",
    "    crop_img = img[loc[0][0]:loc[1][0], loc[0][1]:loc[1][1]]\n",
    "    resized_image = cv2.resize(crop_img, dim)\n",
    "    return resized_image \n",
    "\n",
    "\n",
    "##### training data generation ######\n",
    "\n",
    "def gen_object(target_object, tup):\n",
    "    return_imgs = []\n",
    "    \n",
    "    # backtracking path \n",
    "    t_p = backtrack_tuple(t_p_tuple, path_prefix) \n",
    "    \n",
    "    o_img = cv2.imread(t_p) \n",
    "    # gen cropped obj's\n",
    "    for i in range(2):\n",
    "        r_4 = [random.getrandbits(1) for j in range(4)]\n",
    "        return_imgs.append( \\\n",
    "            img_crop(o_img, loc = \\\n",
    "            [(r_4[0], r_4[1]), \\\n",
    "            (obj_dim - 1 - r_4[2], obj_dim - 1 - r_4[3])] \\\n",
    "            ))\n",
    "        \n",
    "        #### Testing codes\n",
    "        # cv2.imwrite(str(i)+'_test.jpg', return_imgs[i])\n",
    "    return return_imgs\n",
    "\n",
    "def gen_scene_1(target_object, bounds):\n",
    "    \n",
    "    return [np.array([])]\n",
    "\n",
    "##### INPUT FUNC #####\n",
    "\n",
    "def input_func():\n",
    "    # choose target objects randomly\n",
    "    n = 3574\n",
    "    target_obj = random.sample(range(1,n+1),20)\n",
    "    \n",
    "    # init\n",
    "    features = {'object': [], 'scene': []}\n",
    "    labels = []\n",
    "    \n",
    "    for x in target_obj:\n",
    "        #### get xml, otherwise reroll until found \n",
    "        get_xml = bound_xml(x, path_prefix)\n",
    "        while get_xml == (0,0,0,0):\n",
    "            x = random.randint(1, n)\n",
    "            get_xml = bound_xml(x, path_prefix)\n",
    "        \n",
    "        obj_tuple = backtrack_path(x, path_prefix) \n",
    "        #### objects \n",
    "        obj_list = gen_object(x, obj_tuple)\n",
    "        features['objects'].extend(obj_list)\n",
    "        \n",
    "        #### \n",
    "        fts, ls = gen_scene_1(x, get_xml) # 25\n",
    "        features['scenes'].extend(fts) \n",
    "        labels.extend(ls)\n",
    "        \n",
    "        fts, ls = gen_scene_0(x) # 25\n",
    "        features['scenes'].extend(fts) \n",
    "        for i in range(25):\n",
    "            labels.append(0)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 628, 53, 340)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bound_xml((0,1,2), path_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
